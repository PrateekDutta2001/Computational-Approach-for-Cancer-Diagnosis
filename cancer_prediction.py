# -*- coding: utf-8 -*-
"""cancer-prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rF_m6HHeSjsXrwd3RRBUPqkHtr3bFtTm
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

lung_cancer_file_path = '/kaggle/input/lung-cancer/survey lung cancer.csv'

lung_cancer_data = pd.read_csv(lung_cancer_file_path)
lung_cancer_data.describe()

lung_cancer_data.columns

lung_cancer_data.shape

lung_cancer_data.isnull().sum()

lung_cancer_data = lung_cancer_data = lung_cancer_data.dropna(axis=0)
# label encoding
lung_cancer_data.replace({"LUNG_CANCER":{'YES':0,'NO':1}},inplace=True)
# printing the first 5 rows of the dataframe
lung_cancer_data.head(5)

# label encoding
lung_cancer_data.replace({"GENDER":{'M':0,'F':1}},inplace=True)
# printing the first 5 rows of the dataframe
lung_cancer_data.head(5)

import matplotlib.pyplot as plt
import seaborn as sns
plt.figure(figsize = (20, 25))
plotnumber = 1
for column in lung_cancer_data:
    if plotnumber <= 9:
        ax = plt.subplot(3, 3, plotnumber)
        sns.distplot(lung_cancer_data[column])
        plt.xlabel(column, fontsize = 15)
    plotnumber += 1
plt.show()

y = lung_cancer_data.LUNG_CANCER

lung_cancer_datafeatures = ['AGE', 'GENDER', 'SMOKING', 'ANXIETY', 'CHRONIC DISEASE', 'ALCOHOL CONSUMING', 'SHORTNESS OF BREATH']
X = lung_cancer_data[lung_cancer_datafeatures]
X.describe()

X.head()

from sklearn.tree import DecisionTreeRegressor
lung_cancer_model = DecisionTreeRegressor(random_state = 1)
lung_cancer_model.fit(X,y)

print(X.head())

print(lung_cancer_model.predict(X.head()))

predictions = lung_cancer_model.predict(X)
print(predictions)

print(lung_cancer_model.predict(X.head()))

from sklearn.model_selection import train_test_split
# separating into train and testing
X_train, X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=1)
print("Shape of X_train is " ,X_train.shape)
print("Shape of X_test  is " ,X_test.shape)
print("Shape of Y_train is " ,y_train.shape)
print("Shape of Y_test  is " ,y_test.shape)

import pandas as pd
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split

"""Decision Tree Regression"""

train_X, val_X, train_y, val_y = train_test_split(X,y,random_state = 1)

#lung_cancer_model = DecisionTreeRegressor() 
#lung_cancer_model.fit(train_X, y)
lung_cancer_model = DecisionTreeRegressor(random_state=1) 

# Fit Lung Cancer Model with the training data.
lung_cancer_model.fit(train_X, train_y)

val_predictions = lung_cancer_model.predict(val_X)
# print the top few validation predictions
print(X.head())
# print the top few actual prices from validation data
print()

from sklearn.metrics import mean_absolute_error
val_mae = mean_absolute_error(val_predictions, val_y) 
# uncomment following line to see the validation_mae
print(val_mae)

from sklearn.metrics import mean_absolute_error 
from sklearn.tree import DecisionTreeRegressor
def get_mae(max_leaf_nodes, train_X, val_X, train_y, val_y):
    model = DecisionTreeRegressor(max_leaf_nodes = max_leaf_nodes, random_state = 0)
    model.fit(train_X, train_y)
    preds_val = model.predict(val_X)
    mae = mean_absolute_error(val_y, preds_val)
    return(mae)
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
dtc = DecisionTreeClassifier()
dtc.fit(train_X,train_y)
y_pred = dtc.predict(val_X)

dtc_train_accuracy = accuracy_score(train_y, dtc.predict(train_X))
dtc_test_accuracy = accuracy_score(val_y, val_predictions)

print(f"Training Accuracy of Decision Tree Model is: {dtc_train_accuracy}")
print(f"Testing Accuracy of Decision Tree Model is: {dtc_test_accuracy}")

from sklearn.model_selection import GridSearchCV 
grid_params = {
    'criterion':['gini', 'entropy'],
    'max_depth':[3,5,7,10],
    'min_samples_split':range(2,10,1),
    'min_samples_leaf': range(2,10,1)
}
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

grid_search = GridSearchCV(dtc, grid_params, cv = 5, n_jobs = -1, verbose = 1)
grid_search.fit(train_X, train_y)

print(grid_search.best_params_)
print(grid_search.best_score_)

dtc = grid_search.best_estimator_
y_pred = dtc.predict(X_test)
dtc_train_accuracy = accuracy_score(train_y, dtc.predict(train_X))
dtc_test_acc = accuracy_score(y_test, y_pred)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

"""Logistic Prediction Model"""

forest_model = RandomForestRegressor(random_state = 1)
forest_model.fit(train_X, train_y)
lung_preds = forest_model.predict(val_X)
print("Validation MAE for Random Forest Model is: {}".format(mean_absolute_error(val_y, lung_preds)))

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

lr = LogisticRegression()
lr.fit(X_train, y_train)
y_pred = lr.predict(X_test)

lr_train_acc = accuracy_score(y_train, lr.predict(X_train))
lr_test_acc = accuracy_score(y_test, y_pred)

print(f"Training Accuracy of Logistic Regression Model is {lr_train_acc}")
print(f"Test Accuracy of Logistic Regression Model is {lr_test_acc}")

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
print(classification_report(y_test, y_pred))

from sklearn import tree 
plt.figure(figsize = (15,10))
tree.plot_tree(dtc,filled = True)

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
forest_model = RandomForestRegressor(random_state=1)
forest_model.fit(X_train, y_train)
melb_preds = forest_model.predict(val_X)
print(mean_absolute_error(val_y, melb_preds))

from sklearn.ensemble import RandomForestClassifier
rand_clf = RandomForestClassifier(criterion = 'gini', max_depth = 1000, max_features = 'sqrt', min_samples_leaf = 2, min_samples_split = 4, n_estimators = 10000)
rand_clf.fit(X_train, y_train)
y_pred = rand_clf.predict(X_test)
rand_clf_train_acc = accuracy_score(y_train, rand_clf.predict(X_train))
rand_clf_test_acc = accuracy_score(y_test, y_pred)
print(f"Training Accuracy of Random Forest Model is {rand_clf_train_acc}")
print(f"Test Accuracy of Random Forest Model is {rand_clf_test_acc}")

def custom_palette(custom_colors):
    customPalette = sns.set_palette(sns.color_palette(custom_colors))
    sns.palplot(sns.color_palette(custom_colors),size=0.8)
    plt.tick_params(axis='both', labelsize=0, length = 0)
pal = ["#395e66","#387d7a","#32936f","#26a96c","#2bc016"]
custom_palette(pal)

fig, ax = plt.subplots(figsize=(12,10))
sns.heatmap(lung_cancer_data.corr(), annot=True, fmt='.1g', cmap=pal, cbar=False, linewidths=0.5, linecolor='grey');

"""Linear Regression"""

from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train, y_train)

LinearRegressionScore = lr.score(X_test,y_test)
print("Accuracy obtained by Linear Regression model:",LinearRegressionScore*100)

"""Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(n_estimators = 100)
rfc.fit(X_train,y_train)

RandomForestClassifierScore = rfc.score(X_test, y_test)
print("Accuracy obtained by Random Forest Classifier model:",RandomForestClassifierScore*100)

# Confusion Matrix of Random Forest Classifier
from sklearn.metrics import confusion_matrix, classification_report
y_pred_rfc = rfc.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred_rfc)
sns.heatmap(cf_matrix, annot=True, cmap=pal)
plt.title("Confusion Matrix for Random Forest Classifier", fontsize=14, fontname="Helvetica", y=1.03);

from sklearn import metrics
print(metrics.classification_report(y_test, y_pred_rfc))

"""K Neighbor Classifier"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train,y_train)

KNeighborsClassifierScore = knn.score(X_test, y_test)
print("Accuracy obtained by K Neighbors Classifier model:",KNeighborsClassifierScore*100)

# Confustion Matrix 
y_pred_knn = knn.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred_knn)
sns.heatmap(cf_matrix, annot=True, cmap=pal)
plt.title("Confusion Matrix for K Neighbors Classifier", fontsize=14, fontname="Helvetica", y=1.03);

print(metrics.classification_report(y_test, y_pred_knn))

"""XGB Classifier"""

from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(X_train, y_train)

XGBClassifierScore = xgb.score(X_test,y_test)
print("Accuracy obtained by XGB Classifier model:",XGBClassifierScore*100)

y_pred_xgb = xgb.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred_xgb)
sns.heatmap(cf_matrix, annot=True, cmap=pal)
plt.title("Confusion Matrix for XGB Classifier", fontsize=14, fontname="Helvetica", y=1.03);

print(metrics.classification_report(y_test, y_pred_xgb))

"""Gradient Boosting Classifier"""

from sklearn.ensemble import GradientBoostingClassifier
gb = GradientBoostingClassifier()
gb.fit(X_train, y_train)

GradientBoostingClassifierScore = gb.score(X_test,y_test)
print("Accuracy obtained by Gradient Boosting Classifier model:",GradientBoostingClassifierScore*100)

y_pred_gb = gb.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred_gb)
sns.heatmap(cf_matrix, annot=True, cmap=pal)
plt.title("Confusion Matrix for Gradient Boosting Classifier", fontsize=14, fontname="Helvetica", y=1.03);

print(metrics.classification_report(y_test, y_pred_gb))

import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objs as go
import plotly.express as px

plt.style.use("seaborn")
x = ["Linear Regression",  
     "Random Forest Classifier", 
     "K Neighbors Classifier",  
     "XGB Classifier",
     "Gradient Boosting Classifier"]
y = [LinearRegressionScore,  
     RandomForestClassifierScore, 
     KNeighborsClassifierScore,
     XGBClassifierScore,
     GradientBoostingClassifierScore]
fig, ax = plt.subplots(figsize=(12,6))
sns.barplot(x=x,y=y, palette=pal);
plt.ylabel("Model Accuracy")
plt.xticks(rotation=40, fontsize=14)
plt.title("Model Comparison - Model Accuracy", fontsize=20, fontname="Helvetica", y=1.03)
plt.show()

